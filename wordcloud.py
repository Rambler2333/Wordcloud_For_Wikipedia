# -*- coding: utf-8 -*-
"""WordCloud.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zldlJFj_bS-exJt_SCoKvTG347_le3vz
"""

# !python -m spacy download en_core_web_sm
# %pip install wikipedia-api wordcloud pandas matplotlib
import wikipediaapi
from bs4 import BeautifulSoup
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import pandas as pd
import spacy

# Load the English NLP model. "en_core_web_sm" is a small and efficient pre-trained model that is commonly used for basic NLP tasks.
nlp = spacy.load("en_core_web_sm")

def is_non_noun(token):
    return token.pos_ not in ["NOUN"]

def filter(token):
    return not (token.is_stop or token.text.lower() in stop_words or is_non_noun(token))

# additional stop words to elminate useless words
stop_words = ["the", "and", "to", "in", "of", "a", "is", "that", "it", "will", "problem", "use", "used", "many", "make", "find", "increase", "may", "including", "two", "one", "three"]

# Input the Wikipedia page title
page_title = "Python (programming language)"

# Create a instance
myWiki = wikipediaapi.Wikipedia("TestWiki", "en")

# Fetch txt content in the page
page = myWiki.page(page_title)
page_html = page.text

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(page_html, "html.parser")
page_content = soup.get_text()

# Process the extracted text using spaCy "nlp" function
doc = nlp(page_content)

# Apply custom filtering to get professional terms
professional_terms = [token.text for token in doc if filter(token)]

# Tokenize the text (split into words)
words = page_content.split()

# Remove custom stop words
filtered_words = [word for word in words if word.lower() not in stop_words]

# Recreate the processed text
processed_text = " ".join(filtered_words)

# Generate the word cloud from the processed text
wordcloud = WordCloud(width=800, height=400, background_color='lightgray',prefer_horizontal=0.57, font_path='arial_bold.ttf', contour_color='blue', contour_width=2).generate(processed_text)

# Display the word cloud
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()